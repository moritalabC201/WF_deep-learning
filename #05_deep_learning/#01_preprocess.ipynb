{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "date = \"mother_folder\"\n",
    "dl_folder = f\"base_path/{date}_DL\"\n",
    "\n",
    "dl_number = \"project_name\"\n",
    "os.mkdir(f\"{dl_folder}/model_{dl_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_list1 = [\n",
    "                    \"mouse1_ex1\",\n",
    "#                    \"mouse1_ex2\",\n",
    "#                    \"mouse1_ex3\",\n",
    "                    ]\n",
    "mouse_id1 = \"mouse1\"\n",
    "\n",
    "experiments_list2 = [\n",
    "                    \"mouse2_ex1\",\n",
    "#                    \"mouse2_ex2\",\n",
    "#                    \"mouse2_ex3\",\n",
    "                    ]\n",
    "mouse_id2 = \"mouse2\"\n",
    "\n",
    "experiments_list3 = [\n",
    "                    \"mouse3_ex1\",\n",
    "#                    \"mouse3_ex2\",\n",
    "#                    \"mouse3_ex3\",\n",
    "                    ]\n",
    "mouse_id3 = \"mouse3\"\n",
    "\n",
    "\n",
    "ex_list = [\n",
    "            experiments_list1,\n",
    "            experiments_list2, \n",
    "            experiments_list3,  \n",
    "                ]\n",
    "\n",
    "mouse_list = [\n",
    "              mouse_id1,\n",
    "              mouse_id2,\n",
    "              mouse_id3,  \n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 20  # sampling rate\n",
    "look_frame = 30     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def lowpass_filter(data, cutoff):\n",
    "\n",
    "    order = 4  \n",
    "    nyquist = 0.5 * fs  \n",
    "    normal_cutoff = cutoff / nyquist  # normalized cut-off frequency\n",
    "\n",
    "    # Butterworth filter\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "\n",
    "    # applying\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize(data, start_n, end_n):\n",
    "\n",
    "    norm_data = data / np.mean(data[start_n:end_n])\n",
    "    \n",
    "    return norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_velocity(data, dt):\n",
    "     \n",
    "    velocity = []\n",
    "    for frame in range(data.shape[0]-1):\n",
    "        vel_frame = (data[frame+1]-data[frame]) / dt\n",
    "        velocity.append(vel_frame)\n",
    "    velocity = np.array(velocity)\n",
    "\n",
    "    return velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def z_score(data, start_n, end_n):\n",
    "\n",
    "    z_data = (data-np.mean(data[start_n:end_n])) / np.std(data[start_n:end_n])\n",
    "    \n",
    "    return z_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def z_score2(data, start_n, end_n):\n",
    "\n",
    "    z_data = (data-np.mean(data[start_n:end_n])) / np.std(data[start_n:end_n])\n",
    "    \n",
    "    return z_data, np.mean(data[start_n:end_n]), np.std(data[start_n:end_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def z_score3(data, data_base, start_n, end_n):\n",
    "\n",
    "    z_data = (data-np.mean(data_base[start_n:end_n])) / np.std(data_base[start_n:end_n])\n",
    "    \n",
    "    return z_data, np.mean(data_base[start_n:end_n]), np.std(data_base[start_n:end_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def min_max_norm(data):\n",
    "\n",
    "    min_max = (data-min(data)) / (max(data)-min(data))\n",
    "    \n",
    "    return min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def min_max_norm2(data):\n",
    "\n",
    "    min_max = (data-min(data)) / (max(data)-min(data))\n",
    "    \n",
    "    return min_max, min(data), max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_response(data, base_start, base_end):\n",
    "    baseline = np.mean(data[base_start:base_end], axis=0)\n",
    "    response = data - baseline\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1 4 (10, 200)\n",
      "3 1 4 (10, 200)\n",
      "3 1 4 (10, 200)\n",
      "3 1 4 (10, 200)\n",
      "3 1 4 (10, 200)\n",
      "3 1 4 (10, 200)\n",
      "3 1 4 (10, 200)\n",
      "3 1 4 (10, 200)\n",
      "3 1 4 (10, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "no_cycle = 10  # number of cycle\n",
    "pupil_cutoff = 1  # cut-off frequency\n",
    "vis_stim1 = 15    # stimulation start (sec)\n",
    "#vis_stim2 = 25\n",
    "use_range = 5     # range (sec)\n",
    "\n",
    "diameters = []\n",
    "velocities = []\n",
    "accelerations = []\n",
    "for mouse in tqdm.tqdm(range(len(mouse_list))):\n",
    "    diameters1= []\n",
    "    velocities1= []\n",
    "    accelerations1 = []\n",
    "    for ex in range(len(ex_list[mouse])):\n",
    "        diameter1 = []\n",
    "        velocity1 = []\n",
    "        acceleration1, acceleration2 = [], []\n",
    "        for cycle in range(no_cycle):        \n",
    "            diameter = np.load(f\"pupil_folder/{mouse_list[mouse]}/{ex_list[mouse][ex]}/{ex_list[mouse][ex]}_ex0{cycle}.npy\")\n",
    "            diameter = lowpass_filter(data=diameter, cutoff=pupil_cutoff)\n",
    "            n_diameter = normalize(data=diameter, start_n=20, end_n=90)\n",
    "            velocity = calc_velocity(data=n_diameter, dt=1/fs)\n",
    "            acceleration = calc_velocity(data=velocity, dt=1/fs)\n",
    "\n",
    "            temp_dia1 = n_diameter[int(fs*vis_stim1)-int(fs*use_range):int(fs*vis_stim1)+int(fs*use_range)]\n",
    "            #temp_dia2 = n_diameter[int(fs*vis_stim2)-int(fs*use_range):int(fs*vis_stim2)+int(fs*use_range)]\n",
    "            temp_velo1 = velocity[int(fs*vis_stim1)-int(fs*use_range)-1:int(fs*vis_stim1)+int(fs*use_range)-1]\n",
    "            #temp_velo2 = velocity[int(fs*vis_stim2)-int(fs*use_range)-1:int(fs*vis_stim2)+int(fs*use_range)-1]\n",
    "            temp_acc1 = acceleration[int(fs*vis_stim1)-int(fs*use_range)-2:int(fs*vis_stim1)+int(fs*use_range)-2]\n",
    "            #temp_acc2 = acceleration[int(fs*vis_stim2)-int(fs*use_range)-2:int(fs*vis_stim2)+int(fs*use_range)-2]\n",
    "\n",
    "            diameter1.append(temp_dia1)\n",
    "            #diameter2.append(temp_dia2)\n",
    "            velocity1.append(temp_velo1)\n",
    "            #velocity2.append(temp_velo2)\n",
    "            acceleration1.append(temp_acc1)\n",
    "            #acceleration2.append(temp_acc2)\n",
    "\n",
    "\n",
    "        diameters1.append(np.array(diameter1))\n",
    "        #diameters2.append(np.array(diameter2))\n",
    "        velocities1.append(np.array(velocity1))\n",
    "        #velocities2.append(np.array(velocity2))\n",
    "        accelerations1.append(np.array(acceleration1))\n",
    "        #accelerations2.append(np.array(acceleration2))\n",
    "\n",
    "    #diameters.append([diameters1, diameters2])\n",
    "    #velocities.append([velocities1, velocities2])\n",
    "    #accelerations.append([accelerations1, accelerations2])\n",
    "\n",
    "    diameters.append([diameters1])\n",
    "    velocities.append([velocities1])\n",
    "    accelerations.append([accelerations1])\n",
    "\n",
    "#diameters = np.array(diameters)\n",
    "#velocities = np.array(velocities)\n",
    "\n",
    "print(len(diameters), len(diameters[0]), len(diameters[0][0]), diameters[0][0][0].shape)\n",
    "print(len(velocities), len(velocities[0]), len(velocities[0][0]), velocities[0][0][0].shape)\n",
    "print(len(accelerations), len(accelerations[0]), len(accelerations[0][0]), accelerations[0][0][0].shape)\n",
    "print(len(diameters), len(diameters[1]), len(diameters[1][0]), diameters[1][0][0].shape)\n",
    "print(len(velocities), len(velocities[1]), len(velocities[1][0]), velocities[1][0][0].shape)\n",
    "print(len(accelerations), len(accelerations[1]), len(accelerations[1][0]), accelerations[1][0][0].shape)\n",
    "print(len(diameters), len(diameters[2]), len(diameters[2][0]), diameters[2][0][0].shape)\n",
    "print(len(velocities), len(velocities[2]), len(velocities[2][0]), velocities[2][0][0].shape)\n",
    "print(len(accelerations), len(accelerations[2]), len(accelerations[2][0]), accelerations[2][0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 3005.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 3\n",
      "(40, 200) (40, 200) (40, 200)\n",
      "(40, 200) (40, 200) (40, 200)\n",
      "(40, 200) (40, 200) (40, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dia_list, vel_list, acc_list = [], [], []\n",
    "for mouse in tqdm.tqdm(range(len(mouse_list))):\n",
    "    dia_array = np.array(diameters[mouse]).reshape(len(diameters[mouse])*len(diameters[mouse][0])*diameters[mouse][0][0].shape[0], diameters[mouse][0][0].shape[1])\n",
    "    vel_array = np.array(velocities[mouse]).reshape(len(velocities[mouse])*len(velocities[mouse][0])*velocities[mouse][0][0].shape[0], velocities[mouse][0][0].shape[1])\n",
    "    acc_array = np.array(accelerations[mouse]).reshape(len(accelerations[mouse])*len(accelerations[mouse][0])*accelerations[mouse][0][0].shape[0], accelerations[mouse][0][0].shape[1])\n",
    "\n",
    "    dia_list.append(dia_array)\n",
    "    vel_list.append(vel_array)\n",
    "    acc_list.append(acc_array)\n",
    "\n",
    "print(len(dia_list), len(vel_list), len(acc_list))\n",
    "print(dia_list[0].shape, vel_list[0].shape, acc_list[0].shape)\n",
    "print(dia_list[1].shape, vel_list[1].shape, acc_list[1].shape)\n",
    "print(dia_list[2].shape, vel_list[2].shape, acc_list[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 743.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 3\n",
      "(40, 200) (40, 200) (40, 200)\n",
      "(40, 200) (40, 200) (40, 200)\n",
      "(40, 200) (40, 200) (40, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_start, base_end = 85, 95  # frame\n",
    "\n",
    "dia_res, vel_res, acc_res = [], [], []\n",
    "for mouse in tqdm.tqdm(range(len(mouse_list))):\n",
    "    temp_dia, temp_vel, temp_acc = [], [], []\n",
    "    for ex in range(dia_list[mouse].shape[0]):\n",
    "        temp_dia.append(calc_response(dia_list[mouse][ex], base_start, base_end))\n",
    "        temp_vel.append(calc_response(vel_list[mouse][ex], base_start, base_end))\n",
    "        temp_acc.append(calc_response(acc_list[mouse][ex], base_start, base_end))\n",
    "    dia_res.append(np.array(temp_dia))\n",
    "    vel_res.append(np.array(temp_vel))\n",
    "    acc_res.append(np.array(temp_acc))\n",
    "\n",
    "print(len(dia_res), len(vel_res), len(acc_res))\n",
    "print(dia_res[0].shape, vel_res[0].shape, acc_res[0].shape)\n",
    "print(dia_res[1].shape, vel_res[1].shape, acc_res[1].shape)\n",
    "print(dia_res[2].shape, vel_res[2].shape, acc_res[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\user\\.conda\\envs\\deepshap\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n",
      "100%|██████████| 3/3 [00:00<00:00, 207.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 3\n",
      "(40, 200) (40, 200) (40, 200)\n",
      "(40, 200) (40, 200) (40, 200)\n",
      "(40, 200) (40, 200) (40, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_n, end_n = 0, 200  # frame\n",
    "\n",
    "dia_z, vel_z, acc_z = [], [], []\n",
    "for mouse in tqdm.tqdm(range(len(mouse_list))):\n",
    "    temp_dia, temp_vel, temp_acc = [], [], []\n",
    "    for ex in range(dia_res[mouse].shape[0]):\n",
    "        temp_dia.append(z_score(dia_res[mouse][ex], start_n, end_n))\n",
    "        temp_vel.append(z_score(vel_res[mouse][ex], start_n, end_n))\n",
    "        temp_acc.append(z_score(acc_res[mouse][ex], start_n, end_n))\n",
    "    dia_z.append(np.array(temp_dia))\n",
    "    vel_z.append(np.array(temp_vel))\n",
    "    acc_z.append(np.array(temp_acc))\n",
    "\n",
    "print(len(dia_z), len(vel_z), len(acc_z))\n",
    "print(dia_z[0].shape, vel_z[0].shape, acc_z[0].shape)\n",
    "print(dia_z[1].shape, vel_z[1].shape, acc_z[1].shape)\n",
    "print(dia_z[2].shape, vel_z[2].shape, acc_z[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\user\\.conda\\envs\\deepshap\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n",
      "100%|██████████| 3/3 [00:00<00:00, 95.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 3\n",
      "(40, 200) (40, 200) (40, 200)\n",
      "(40, 200) (40, 200) (40, 200)\n",
      "(40, 200) (40, 200) (40, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dia_mm, vel_mm, acc_mm = [], [], []\n",
    "for mouse in tqdm.tqdm(range(len(mouse_list))):\n",
    "    temp_dia, temp_vel, temp_acc = [], [], []\n",
    "    for ex in range(dia_res[mouse].shape[0]):\n",
    "        temp_dia.append(min_max_norm(dia_res[mouse][ex]))\n",
    "        temp_vel.append(min_max_norm(vel_res[mouse][ex]))\n",
    "        temp_acc.append(min_max_norm(acc_res[mouse][ex]))\n",
    "    dia_mm.append(np.array(temp_dia))\n",
    "    vel_mm.append(np.array(temp_vel))\n",
    "    acc_mm.append(np.array(temp_acc))\n",
    "\n",
    "print(len(dia_mm), len(vel_mm), len(acc_mm))\n",
    "print(dia_mm[0].shape, vel_mm[0].shape, acc_mm[0].shape)\n",
    "print(dia_mm[1].shape, vel_mm[1].shape, acc_mm[1].shape)\n",
    "print(dia_mm[2].shape, vel_mm[2].shape, acc_mm[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refer_pupil = dia_mm  # selected data of pupil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 119, 200)\n"
     ]
    }
   ],
   "source": [
    "ca_list2 = np.load(\"D:/Python_TK_3/datas/251126_ica/251110-251121_ss_v01/ic_temporal_components_extracted.npy\")\n",
    "print(ca_list2.shape)  #(models, experiments, components, frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119, 10, 200)\n"
     ]
    }
   ],
   "source": [
    "ca_list2 = ca_list2.transpose(1, 0, 2)\n",
    "print(ca_list2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(40, 10, 200) (40, 10, 200) (39, 10, 200)\n"
     ]
    }
   ],
   "source": [
    "use_cal = [ca_list2[:refer_pupil[0].shape[0]], ca_list2[refer_pupil[0].shape[0] : refer_pupil[0].shape[0]+refer_pupil[1].shape[0]], ca_list2[refer_pupil[0].shape[0]+refer_pupil[1].shape[0] : refer_pupil[0].shape[0]+refer_pupil[1].shape[0]+refer_pupil[2].shape[0]]]\n",
    "\n",
    "print(len(use_cal))\n",
    "print(use_cal[0].shape, use_cal[1].shape, use_cal[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 17.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 60) (40, 60, 10) (40, 60, 10)\n",
      "(40, 60) (40, 60, 10) (40, 60, 10)\n",
      "(39, 60) (39, 60, 10) (39, 60, 10)\n",
      "(119, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "back_second = 1.0  # time before peak\n",
    "forward_second = 0.5  # time after peak\n",
    "stim_frame = 100  # time_frame of stimulation\n",
    "pupil_thresh = 0.6\n",
    "\n",
    "pupil_list = []\n",
    "cortex_list = []\n",
    "index_list =[]\n",
    "corr_array = []\n",
    "for mouse in tqdm.tqdm(range(len(mouse_list))):\n",
    "    binary_pupil = []\n",
    "    extracted_signal = []\n",
    "    extracted_z_area = []\n",
    "    max_idxs = []\n",
    "    for ex in range(refer_pupil[mouse].shape[0]):\n",
    "        max_idx = np.argmax(refer_pupil[mouse][ex, stim_frame+5:stim_frame+15]) + stim_frame+5\n",
    "        extracted_pupil = refer_pupil[mouse][ex, max_idx-int(fs*back_second)-look_frame:max_idx+int(fs*forward_second)]\n",
    "        use_calcium = use_cal[mouse][ex]\n",
    "        extracted_ca   = use_calcium[:, max_idx-int(fs*back_second)-look_frame:max_idx+int(fs*forward_second)]\n",
    "\n",
    "        temp_corr = []\n",
    "        for comp in range(extracted_ca.shape[0]):\n",
    "            temp_corr.append(np.corrcoef(extracted_pupil[look_frame:], extracted_ca[comp, look_frame:])[0, 1])\n",
    "\n",
    "        temp_p = []\n",
    "        for f in range(extracted_pupil.shape[0]):\n",
    "            if extracted_pupil[f] > pupil_thresh:\n",
    "                temp_p.append(1)\n",
    "            else:\n",
    "                temp_p.append(0)\n",
    "\n",
    "        binary_pupil.append(temp_p)\n",
    "        max_idxs.append(max_idx)\n",
    "        extracted_signal.append(extracted_ca.transpose())\n",
    "        corr_array.append(temp_corr)\n",
    "\n",
    "    binary_pupil = np.array(binary_pupil)\n",
    "    extracted_signal = np.array(extracted_signal)\n",
    "\n",
    "    pupil_list.append(binary_pupil)\n",
    "    cortex_list.append(extracted_signal)\n",
    "    index_list.append(max_idxs)\n",
    "\n",
    "corr_array = np.array(corr_array)\n",
    "\n",
    "print(pupil_list[0].shape, cortex_list[0].shape, area_list[0].shape)\n",
    "print(pupil_list[1].shape, cortex_list[1].shape, area_list[1].shape)\n",
    "print(pupil_list[2].shape, cortex_list[2].shape, area_list[2].shape)\n",
    "print(corr_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "5\n",
      "0.0739821496075361\n"
     ]
    }
   ],
   "source": [
    "mean_corr = np.mean(corr_array, axis=0)\n",
    "print(mean_corr.shape)\n",
    "print(np.argmax(mean_corr))\n",
    "print(mean_corr[np.argmax(mean_corr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 231.37it/s]\n"
     ]
    }
   ],
   "source": [
    "Pupil_data = pupil_list\n",
    "signal = cortex_list\n",
    "\n",
    "peak_frame = int(fs*back_second)\n",
    "\n",
    "target = []\n",
    "feature = []\n",
    "experiment_list = []\n",
    "mean_array, std_array = [], []\n",
    "min_array, max_array = [], []\n",
    "\n",
    "pupil_peaks = []\n",
    "cortex_peaks = []\n",
    "\n",
    "for mouse in tqdm.tqdm(range(len(mouse_list))):\n",
    "    temp_target = []\n",
    "    temp_feature = []\n",
    "    temp_experiment_list = []\n",
    "    temp_pupil, temp_cortex = [], []\n",
    "    temp_mean, temp_std = [], []\n",
    "    temp_min, temp_max = [], []\n",
    "    for ex in range(Pupil_data[mouse].shape[0]):\n",
    "        peak_pupil = max(refer_pupil[mouse][ex])\n",
    "        peak_cortex = max(area_list[mouse][ex, :, area])\n",
    "        temp_pupil.append(peak_pupil)\n",
    "        temp_cortex.append(peak_cortex)   \n",
    "        if np.count_nonzero(Pupil_data[mouse][ex, look_frame:] == 1) > 10 and np.all(Pupil_data[mouse][ex, look_frame:look_frame+peak_frame-18] == 0):     \n",
    "            temp_target.append(Pupil_data[mouse][ex])\n",
    "            temp_feature.append(signal[mouse][ex].transpose())\n",
    "            temp_experiment_list.append(ex)\n",
    "        temp_mean.append(means[mouse][ex])\n",
    "        temp_std.append(stds[mouse][ex])\n",
    "        temp_min.append(mins[mouse][ex])\n",
    "        temp_max.append(maxs[mouse][ex])\n",
    "\n",
    "    target.append(np.array(temp_target))\n",
    "    feature.append(np.array(temp_feature))\n",
    "    experiment_list.append(np.array(temp_experiment_list))\n",
    "    mean_array.append(np.array(temp_mean))\n",
    "    std_array.append(np.array(temp_std))\n",
    "    min_array.append(np.array(temp_min))\n",
    "    max_array.append(np.array(temp_max))\n",
    "\n",
    "    pupil_peaks.append(temp_pupil)\n",
    "    cortex_peaks.append(temp_cortex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 60) (17, 10, 60) (17,)\n",
      "(13, 60) (13, 10, 60) (13,)\n",
      "(12, 60) (12, 10, 60) (12,)\n"
     ]
    }
   ],
   "source": [
    "Pupil_data = target\n",
    "signal = feature\n",
    "experiment_list = experiment_list\n",
    "\n",
    "print(Pupil_data[0].shape, signal[0].shape, experiment_list[0].shape)\n",
    "print(Pupil_data[1].shape, signal[1].shape, experiment_list[1].shape)\n",
    "print(Pupil_data[2].shape, signal[2].shape, experiment_list[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37058823529411766\n",
      "0.35512820512820514\n",
      "0.34444444444444444\n"
     ]
    }
   ],
   "source": [
    "for mouse in range(len(Pupil_data)):\n",
    "    print(np.sum(Pupil_data[mouse].reshape(-1))/len(Pupil_data[mouse].reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,) [0.425      0.325      0.30769231]\n",
      "(3,) [0.37058824 0.35512821 0.34444444]\n"
     ]
    }
   ],
   "source": [
    "ex_numbers0, ex_numbers1, ex_numbers2 = pupil_list[0].shape[0], pupil_list[1].shape[0], pupil_list[2].shape[0]\n",
    "\n",
    "ex_rate = np.array([\n",
    "                    experiment_list[0].shape[0]/ex_numbers0,\n",
    "                    experiment_list[1].shape[0]/ex_numbers1,\n",
    "                    experiment_list[2].shape[0]/ex_numbers2,\n",
    "                    ])\n",
    "\n",
    "posi_rate = np.array([\n",
    "                        np.sum(Pupil_data[0].reshape(-1))/len(Pupil_data[0].reshape(-1)),\n",
    "                        np.sum(Pupil_data[1].reshape(-1))/len(Pupil_data[1].reshape(-1)),\n",
    "                        np.sum(Pupil_data[2].reshape(-1))/len(Pupil_data[2].reshape(-1)),\n",
    "                        ])\n",
    "\n",
    "print(ex_rate.shape, ex_rate)\n",
    "print(posi_rate.shape, posi_rate)\n",
    "\n",
    "np.save(f\"{dl_folder}/model_{dl_number}/{date}_{dl_number}_ex_rate.npy\", ex_rate)\n",
    "np.save(f\"{dl_folder}/model_{dl_number}/{date}_{dl_number}_positive_rate.npy\", posi_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  4  6  8  9 10 11 13 15 18 20 22 24 25 27 30 31]\n",
      "[ 0  2  3  4  6 11 17 20 27 29 30 34 37]\n",
      "[ 5  7  9 11 12 13 14 16 19 20 21 24]\n"
     ]
    }
   ],
   "source": [
    "print(experiment_list[0])\n",
    "print(experiment_list[1])\n",
    "print(experiment_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "mouse = 0\n",
    "random.seed(123)\n",
    "\n",
    "# shuffle ex numbers\n",
    "numbers = list(range(experiment_list[mouse].shape[0]))\n",
    "random.shuffle(numbers)\n",
    "\n",
    "# slice ex numbers array\n",
    "dataset1 = numbers[0:4]\n",
    "dataset2 = numbers[4:8]\n",
    "dataset3 = numbers[8:11]\n",
    "dataset4 = numbers[11:14]\n",
    "dataset5 = numbers[14:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "vars_lists = [dataset1, dataset2, dataset3, dataset4, dataset5]\n",
    "\n",
    "splits1 = []\n",
    "# pick up 4 groups\n",
    "for group4 in itertools.combinations(vars_lists, 4):\n",
    "    remaining = [v for v in vars_lists if v not in group4]\n",
    "    splits1.append([\n",
    "        list(group4),\n",
    "        remaining,\n",
    "    ])\n",
    "\n",
    "# check\n",
    "for i, pat in enumerate(splits1[:5], 1):\n",
    "    four, one_a = pat\n",
    "    print(f\"{i:2d}:\")\n",
    "    print(\"  training data\", four)\n",
    "    print(\"  validation data→\", one_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "mouse = 1\n",
    "random.seed(60)\n",
    "\n",
    "# shuffle ex numbers\n",
    "numbers = list(range(experiment_list[mouse].shape[0]))\n",
    "random.shuffle(numbers)\n",
    "\n",
    "# slice ex numbers array\n",
    "dataset1 = numbers[0:4]\n",
    "dataset2 = numbers[4:8]\n",
    "dataset3 = numbers[8:11]\n",
    "dataset4 = numbers[11:14]\n",
    "dataset5 = numbers[14:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "vars_lists = [dataset1, dataset2, dataset3, dataset4, dataset5]\n",
    "\n",
    "splits1 = []\n",
    "# pick up 4 groups\n",
    "for group4 in itertools.combinations(vars_lists, 4):\n",
    "    remaining = [v for v in vars_lists if v not in group4]\n",
    "    splits1.append([\n",
    "        list(group4),\n",
    "        remaining,\n",
    "    ])\n",
    "\n",
    "# check\n",
    "for i, pat in enumerate(splits1[:5], 1):\n",
    "    four, one_a = pat\n",
    "    print(f\"{i:2d}:\")\n",
    "    print(\"  training data\", four)\n",
    "    print(\"  validation data→\", one_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "mouse = 2\n",
    "random.seed(30)\n",
    "\n",
    "# shuffle ex numbers\n",
    "numbers = list(range(experiment_list[mouse].shape[0]))\n",
    "random.shuffle(numbers)\n",
    "\n",
    "# slice ex numbers array\n",
    "dataset1 = numbers[0:4]\n",
    "dataset2 = numbers[4:8]\n",
    "dataset3 = numbers[8:11]\n",
    "dataset4 = numbers[11:14]\n",
    "dataset5 = numbers[14:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "vars_lists = [dataset1, dataset2, dataset3, dataset4, dataset5]\n",
    "\n",
    "splits1 = []\n",
    "# pick up 4 groups\n",
    "for group4 in itertools.combinations(vars_lists, 4):\n",
    "    remaining = [v for v in vars_lists if v not in group4]\n",
    "    splits1.append([\n",
    "        list(group4),\n",
    "        remaining,\n",
    "    ])\n",
    "\n",
    "# check\n",
    "for i, pat in enumerate(splits1[:5], 1):\n",
    "    four, one_a = pat\n",
    "    print(f\"{i:2d}:\")\n",
    "    print(\"  training data\", four)\n",
    "    print(\"  validation data→\", one_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_list = [splits1, splits2, splits3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{dl_folder}/model_{dl_number}/{date}_{dl_number}_selected_experiments_mouse1.npy\", np.array(experiment_list[0]))\n",
    "np.save(f\"{dl_folder}/model_{dl_number}/{date}_{dl_number}_selected_experiments_mouse2.npy\", np.array(experiment_list[1]))\n",
    "np.save(f\"{dl_folder}/model_{dl_number}/{date}_{dl_number}_selected_experiments_mouse3.npy\", np.array(experiment_list[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# Create input data [-n, 0]\n",
    "def create_dataset(dataset, look_frame):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(look_frame, len(dataset)):\n",
    "        xset = []\n",
    "        for j in range(dataset.shape[1]-1):\n",
    "            a = dataset[(i-look_frame):(i+1), j]\n",
    "            xset.append(a)\n",
    "        dataY.append(dataset[i, -1])      \n",
    "        dataX.append(xset)\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetframe = 0\n",
    "\n",
    "def Data_preprocess(signal, pupil):\n",
    "    if targetframe >= 0:\n",
    "        signal = numpy.array(signal).transpose()\n",
    "        pupil = [[x] for x in numpy.array(pupil)]\n",
    "        moved_pupil = pupil.copy()\n",
    "        del moved_pupil[:targetframe]\n",
    "    else:\n",
    "        signal = numpy.array(signal).transpose()\n",
    "        pupil = [[x] for x in numpy.array(pupil)]\n",
    "        moved_pupil = pupil.copy()\n",
    "        del moved_pupil[targetframe:]\n",
    "    pupil =  numpy.array(moved_pupil)\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = numpy.hstack([signal.astype('float32'), pupil.astype('float32')])\n",
    "    X, Y = create_dataset(dataset, look_frame)\n",
    "\n",
    "    positive_rate = pupil.sum() / len(pupil)\n",
    "\n",
    "    return X, Y, positive_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_mouse(mouse, signal, Pupil_data, model):\n",
    "    splits = splits_list[mouse]\n",
    "    signal = signal[mouse]\n",
    "    Pupil_data = Pupil_data[mouse]\n",
    "\n",
    "    flat_list = [x for sublist in splits[model][0] for x in sublist]\n",
    "    train_numbers = sorted(flat_list)\n",
    "    valid_numbers = splits[model][1][0]\n",
    "\n",
    "    np.save(f\"{save_dir}/{date}_{dl_number}_train_numbers_mouse{mouse}.npy\", np.array(train_numbers))\n",
    "    np.save(f\"{save_dir}/{date}_{dl_number}_valid_numbers_mouse{mouse}.npy\", np.array(valid_numbers))\n",
    "\n",
    "    TRratio_Ca = [signal[i] for i in train_numbers]\n",
    "    VAratio_Ca = [signal[i] for i in valid_numbers]\n",
    "    TRPupil_data = [Pupil_data[i] for i in train_numbers]\n",
    "    VAPupil_data = [Pupil_data[i] for i in valid_numbers]\n",
    "\n",
    "    TR_signal_array = np.array(TRratio_Ca).transpose(1, 0, 2)\n",
    "    TR_signal_array = TR_signal_array.reshape(TR_signal_array.shape[0], TR_signal_array.shape[1]*TR_signal_array.shape[2])\n",
    "\n",
    "    # Training dataset\n",
    "    trainX = numpy.empty([0, signal.shape[1], look_frame+1], dtype=numpy.float32)\n",
    "    trainY = numpy.empty(0, dtype=numpy.float32)\n",
    "    pr_tr = []\n",
    "    for i in list(range(len(train_numbers))):\n",
    "        X, Y, pr = Data_preprocess(TRratio_Ca[i], TRPupil_data[i])\n",
    "        trainX = numpy.concatenate([trainX, X], axis=0)\n",
    "        trainY = numpy.concatenate([trainY, Y], axis=0)\n",
    "        pr_tr.append(pr)\n",
    "\n",
    "    # Training dataset\n",
    "    validX = numpy.empty([0, signal.shape[1], look_frame+1], dtype=numpy.float32)\n",
    "    validY = numpy.empty(0, dtype=numpy.float32)\n",
    "    pr_va = []\n",
    "    for i in list(range(len(valid_numbers))):\n",
    "        X, Y, pr = Data_preprocess(VAratio_Ca[i], VAPupil_data[i])\n",
    "        validX = numpy.concatenate([validX, X], axis=0)\n",
    "        validY = numpy.concatenate([validY, Y], axis=0)\n",
    "        pr_va.append(pr)\n",
    "\n",
    "    # Transpose input\n",
    "    input_train = trainX.transpose(0,2,1)\n",
    "    input_valid = validX.transpose(0,2,1)\n",
    "\n",
    "    posi_rate = np.array([sum(pr_tr)/len(pr_tr), sum(pr_va)/len(pr_va)])\n",
    "\n",
    "\n",
    "    return input_train, input_valid, trainY, validY, TR_signal_array, posi_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:00<00:00, 18.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39285714 0.26666667]\n",
      "[0.33636364 0.45833333]\n",
      "[0.37333333 0.2       ]\n",
      "[0.33095238 0.55555556]\n",
      "[0.33939394 0.44166667]\n",
      "[0.35666667 0.28333333]\n",
      "[0.3702381  0.37222222]\n",
      "[0.36666667 0.31666667]\n",
      "[0.36       0.26666667]\n",
      "[0.40512821 0.25833333]\n",
      "[0.37166667 0.3       ]\n",
      "[0.30925926 0.45      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35512821 0.42083333]\n",
      "[0.365      0.32222222]\n",
      "[0.31666667 0.42777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import numpy\n",
    "\n",
    "no_mouse = 3\n",
    "ex_frames = 30  # frames per experiment\n",
    "\n",
    "\n",
    "for n in tqdm.tqdm(range(len(splits1))):\n",
    "    save_dir = os.path.join(os.path.join(dl_folder, f\"model_{dl_number}\"), f\"model_{n}\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for mouse in range(no_mouse):\n",
    "        temp_train, temp_valid, temp_trY, temp_vaY, temp_tr_sig, temp_posi = multi_mouse(mouse, signal, Pupil_data, model=n)\n",
    "        print(temp_posi)\n",
    "        if mouse == 0:\n",
    "            input_train, input_valid, trainY, validY, TR_signal_array  = temp_train, temp_valid, temp_trY, temp_vaY, temp_tr_sig\n",
    "        else:\n",
    "            input_train = np.concatenate((input_train, temp_train), axis=0)\n",
    "            input_valid = np.concatenate((input_valid, temp_valid), axis=0)\n",
    "            trainY = np.concatenate((trainY, temp_trY), axis=0)\n",
    "            validY = np.concatenate((validY, temp_vaY), axis=0)\n",
    "            TR_signal_array = np.concatenate((TR_signal_array, temp_tr_sig), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    signal_min = []\n",
    "    signal_max = []\n",
    "    signal_ave = []\n",
    "    signal_std = []\n",
    "    for area in range(TR_signal_array.shape[0]):\n",
    "        signal_min.append(min(TR_signal_array[area]))\n",
    "        signal_max.append(max(TR_signal_array[area]))\n",
    "        signal_ave.append(np.mean(TR_signal_array[area]))\n",
    "        signal_std.append(np.std(TR_signal_array[area]))\n",
    "    signal_min = np.array(signal_min)\n",
    "    signal_max = np.array(signal_max)\n",
    "    signal_ave = np.array(signal_ave)\n",
    "    signal_std = np.array(signal_std)\n",
    "\n",
    "    np.save(f\"{save_dir}/{date}_{dl_number}_train_signal_min.npy\", signal_min)\n",
    "    np.save(f\"{save_dir}/{date}_{dl_number}_train_signal_max.npy\", signal_max)\n",
    "    np.save(f\"{save_dir}/{date}_{dl_number}_train_signal_ave.npy\", signal_ave)\n",
    "    np.save(f\"{save_dir}/{date}_{dl_number}_train_signal_std.npy\", signal_std)\n",
    "\n",
    "    # shuffle train y labels\n",
    "    #ex_no = int(input_train.shape[0]/ex_frames)\n",
    "    #for ex in range(ex_no):\n",
    "    #    copy_array = trainY[ex*ex_frames:(ex+1)*ex_frames].copy()\n",
    "    #    np.random.shuffle(copy_array)\n",
    "    #    trainY[ex*ex_frames:(ex+1)*ex_frames] = copy_array\n",
    "\n",
    "    np.save(f\"{save_dir}/{date}_{dl_number}_train_features.npy\", input_train)\n",
    "    np.save(f\"{save_dir}/{date}_{dl_number}_train_targets.npy\", trainY)\n",
    "    np.save(f\"{save_dir}/{date}_{dl_number}_valid_features.npy\", input_valid)\n",
    "    np.save(f\"{save_dir}/{date}_{dl_number}_valid_targets.npy\", validY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepshap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
