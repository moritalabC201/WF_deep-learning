{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Version for filename\n",
    "ver = 'GRU'  # GRU or LSTM\n",
    "\n",
    "date = \"mother_folder\"\n",
    "dl_folder = f\"base_path/{date}_DL\"\n",
    "\n",
    "dl_number = \"project_name\"\n",
    "#os.mkdir(f\"{dl_folder}/model_{dl_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 20  # sampling rate\n",
    "look_frame = 30  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warning\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "import numpy\n",
    "#import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import io\n",
    "from tensorflow.keras import layers, losses, optimizers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, ConvLSTM2D, Bidirectional\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow grouth option of GPU\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Clear session\n",
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 97.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "val_loss_list = []\n",
    "for n in tqdm.tqdm(range(5)):\n",
    "    model_dir = os.path.join(os.path.join(dl_folder, f\"model_{dl_number}\"), f\"model_{n}\")\n",
    "    val_loss = np.load(os.path.join(model_dir, f\"valid_loss.npy\"))\n",
    "    val_loss_list.append(val_loss)\n",
    "\n",
    "val_loss_list = np.array(val_loss_list)\n",
    "\n",
    "print(val_loss_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "def _predict_for_score(model, X):\n",
    "    # sklearn\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        proba = np.asarray(model.predict_proba(X))\n",
    "\n",
    "        if proba.ndim == 2 and proba.shape[1] == 1:\n",
    "            return proba[:, 0]  \n",
    "\n",
    "        if proba.ndim == 2 and proba.shape[1] >= 2:\n",
    "            return proba[:, 1]\n",
    "        return proba.ravel()\n",
    "\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        return np.asarray(model.decision_function(X)).ravel()\n",
    "\n",
    "\n",
    "    yhat = np.asarray(model.predict(X))\n",
    "    return yhat.ravel()\n",
    "\n",
    "def permutation_importance_time_feature(\n",
    "    model, X, y, score_fn, n_repeats=5, random_state=0\n",
    "):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    base_pred = _predict_for_score(model, X)\n",
    "    baseline = score_fn(y, base_pred)\n",
    "\n",
    "    n, T, F = X.shape\n",
    "    drops = np.zeros((T, F, n_repeats), dtype=float)\n",
    "\n",
    "    for t in range(T):\n",
    "        for f in range(F):\n",
    "            for r in range(n_repeats):\n",
    "                perm = rng.permutation(n)\n",
    "                Xp = X.copy()\n",
    "                Xp[:, t, f] = X[perm, t, f]  \n",
    "                pred = _predict_for_score(model, Xp)\n",
    "                drops[t, f, r] = baseline - score_fn(y, pred)\n",
    "\n",
    "    return baseline, drops.mean(axis=2), drops.std(axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [14:35<00:00, 175.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "(5, 31, 10) (5, 31, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baselines = []\n",
    "importance, std_imp = [], []\n",
    "for n in tqdm.tqdm(range(5)):\n",
    "    model_dir = os.path.join(os.path.join(dl_folder, f\"model_{dl_number}\"), f\"model_{n}\")\n",
    "\n",
    "\n",
    "    epoch = val_loss_list[n].argmin() + 1\n",
    "    if epoch > 9:\n",
    "        model_file_path = os.path.join(\n",
    "            model_dir,\n",
    "            f\"{date}_{dl_number}_ver{ver}_epoch{epoch}.h5\"\n",
    "        )\n",
    "\n",
    "    if epoch < 10:\n",
    "        model_file_path = os.path.join(\n",
    "            model_dir,\n",
    "            f\"{date}_{dl_number}_ver{ver}_epoch0{epoch}.h5\"\n",
    "        )        \n",
    "\n",
    "    model = load_model(model_file_path)\n",
    "\n",
    "    input_valid = np.load(f\"{model_dir}/{date}_{dl_number}_valid_features.npy\")\n",
    "    validY = np.load(f\"{model_dir}/{date}_{dl_number}_valid_targets.npy\")\n",
    "\n",
    "    baseline, drops_mean, drops_std = permutation_importance_time_feature(model, input_valid, validY, score_fn=roc_auc_score, n_repeats=3, random_state=0)\n",
    "\n",
    "    baselines.append(baseline)\n",
    "    importance.append(drops_mean)\n",
    "    std_imp.append(drops_std)\n",
    "\n",
    "\n",
    "baselines = np.array(baselines)\n",
    "importance = np.array(importance)\n",
    "std_imp = np.array(std_imp)\n",
    "\n",
    "print(baselines.shape)\n",
    "print(importance.shape, std_imp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save((f\"{dl_folder}/model_{dl_number}/{date}_{dl_number}_valid_pemutation_importance.npy\"), importance)\n",
    "np.save((f\"{dl_folder}/model_{dl_number}/{date}_{dl_number}_valid_pemutation_importance_std.npy\"), std_imp)\n",
    "np.save((f\"{dl_folder}/model_{dl_number}/{date}_{dl_number}_valid_pemutation_importance_baseline.npy\"), baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepshap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
